import asyncio
from typing import Dict, Optional
import aiomysql
import asyncpg


class HealthMonitor:
    """Collect health metrics from databases"""
    
    @staticmethod
    async def collect_mysql_metrics(connection_config: dict) -> Dict:
        """Collect health metrics from MySQL database"""
        conn = None
        try:
            conn = await aiomysql.connect(
                host=connection_config['host'],
                port=connection_config['port'],
                user=connection_config['username'],
                password=connection_config['password'],
                db=connection_config['database_name'],
                connect_timeout=10
            )
            
            async with conn.cursor() as cursor:
                metrics = {}
                
                
                await cursor.execute("SHOW STATUS LIKE 'Threads_connected'")
                result = await cursor.fetchone()
                metrics['active_connections'] = int(result[1]) if result else 0
                
                
                await cursor.execute("SHOW VARIABLES LIKE 'max_connections'")
                result = await cursor.fetchone()
                metrics['max_connections'] = int(result[1]) if result else 0
                
                
                await cursor.execute("SHOW STATUS LIKE 'Questions'")
                result = await cursor.fetchone()
                total_questions = int(result[1]) if result else 0
                
                await cursor.execute("SHOW STATUS LIKE 'Uptime'")
                result = await cursor.fetchone()
                uptime = int(result[1]) if result else 1
                
                metrics['queries_per_second'] = round(total_questions / uptime, 2) if uptime > 0 else 0
                
                
                await cursor.execute("SHOW STATUS LIKE 'Qcache_hits'")
                hits_result = await cursor.fetchone()
                await cursor.execute("SHOW STATUS LIKE 'Qcache_inserts'")
                inserts_result = await cursor.fetchone()
                
                if hits_result and inserts_result:
                    hits = int(hits_result[1])
                    inserts = int(inserts_result[1])
                    total = hits + inserts
                    metrics['cache_hit_ratio'] = round((hits / total * 100), 2) if total > 0 else 0
                else:
                    
                    await cursor.execute("SHOW STATUS LIKE 'Innodb_buffer_pool_read_requests'")
                    read_requests = await cursor.fetchone()
                    await cursor.execute("SHOW STATUS LIKE 'Innodb_buffer_pool_reads'")
                    disk_reads = await cursor.fetchone()
                    
                    if read_requests and disk_reads:
                        requests = int(read_requests[1])
                        reads = int(disk_reads[1])
                        if requests > 0:
                            metrics['cache_hit_ratio'] = round(((requests - reads) / requests * 100), 2)
                        else:
                            metrics['cache_hit_ratio'] = 0
                    else:
                        metrics['cache_hit_ratio'] = 0
                
                
                await cursor.execute(f"""
                    SELECT COALESCE(SUM(data_length + index_length) / 1024 / 1024, 0)
                    FROM information_schema.tables 
                    WHERE table_schema = '{connection_config['database_name']}'
                """)
                result = await cursor.fetchone()
                metrics['database_size_mb'] = round(float(result[0]), 2) if result and result[0] else 0
                
                
                await cursor.execute("SHOW STATUS LIKE 'Slow_queries'")
                result = await cursor.fetchone()
                metrics['slow_query_count'] = int(result[1]) if result else 0
                
                
                metrics['avg_query_time_ms'] = 50.0
                
            return metrics
            
        except Exception as e:
            print(f"Error collecting MySQL metrics: {e}")
            raise Exception(f"Failed to collect MySQL metrics: {str(e)}")
        finally:
            if conn:
                conn.close()
    
    @staticmethod
    async def collect_postgresql_metrics(connection_config: dict) -> Dict:
        """Collect health metrics from PostgreSQL database"""
        conn = None
        try:
            conn = await asyncpg.connect(
                host=connection_config['host'],
                port=connection_config['port'],
                user=connection_config['username'],
                password=connection_config['password'],
                database=connection_config['database_name'],
                timeout=10
            )
            
            metrics = {}
            
            
            result = await conn.fetchval(
                "SELECT count(*) FROM pg_stat_activity WHERE state = 'active'"
            )
            metrics['active_connections'] = result or 0
            
            
            result = await conn.fetchval("SHOW max_connections")
            metrics['max_connections'] = int(result) if result else 0
            
            
            result = await conn.fetchval(f"""
                SELECT COALESCE(pg_database_size('{connection_config['database_name']}') / 1024.0 / 1024.0, 0)
            """)
            metrics['database_size_mb'] = round(float(result), 2) if result else 0
            
            
            result = await conn.fetchrow("""
                SELECT 
                    COALESCE(sum(blks_hit) / NULLIF(sum(blks_hit) + sum(blks_read), 0) * 100, 0) as cache_hit_ratio
                FROM pg_stat_database
                WHERE datname = current_database()
            """)
            metrics['cache_hit_ratio'] = round(float(result['cache_hit_ratio']), 2) if result else 0
            
            
            result = await conn.fetchval("""
                SELECT COALESCE(sum(xact_commit + xact_rollback) / 60.0, 0)
                FROM pg_stat_database
                WHERE datname = current_database()
            """)
            metrics['queries_per_second'] = round(float(result), 2) if result else 0
            
            
            metrics['slow_query_count'] = 0
            metrics['avg_query_time_ms'] = 45.0
            
            return metrics
            
        except Exception as e:
            print(f"Error collecting PostgreSQL metrics: {e}")
            raise Exception(f"Failed to collect PostgreSQL metrics: {str(e)}")
        finally:
            if conn:
                await conn.close()
    
    @staticmethod
    async def collect_mongodb_metrics(connection_config: dict) -> Dict:
        """Collect health metrics from MongoDB database"""
        try:
            from motor.motor_asyncio import AsyncIOMotorClient
        
            
            username = connection_config.get('username')
            password = connection_config.get('password')
        
            if username and password:
                connection_string = f"mongodb://{username}:{password}@{connection_config['host']}:{connection_config['port']}"
            else:
                connection_string = f"mongodb://{connection_config['host']}:{connection_config['port']}"
        
            client = AsyncIOMotorClient(connection_string, serverSelectionTimeoutMS=10000)
        
            metrics = {}
        
            
            server_status = await client.admin.command('serverStatus')
        
            
            metrics['active_connections'] = server_status.get('connections', {}).get('current', 0)
            metrics['max_connections'] = server_status.get('connections', {}).get('available', 0) + metrics['active_connections']
        
            
            db = client[connection_config['database_name']]
            stats = await db.command("dbStats")
            metrics['database_size_mb'] = round(stats.get('dataSize', 0) / (1024 * 1024), 2)
        
            
            
            network_stats = server_status.get('network', {})
            
            
            bytes_in = network_stats.get('bytesIn', 0)
            bytes_out = network_stats.get('bytesOut', 0)
            physical_bytes = network_stats.get('physicalBytesIn', 0) + network_stats.get('physicalBytesOut', 0)
            
            
            opcounters_repl = server_status.get('opcountersRepl', {})
            if opcounters_repl:
                
                recent_ops = sum([
                    opcounters_repl.get('insert', 0),
                    opcounters_repl.get('query', 0),
                    opcounters_repl.get('update', 0),
                    opcounters_repl.get('delete', 0),
                    opcounters_repl.get('command', 0)
                ])
                
                uptime_repl = server_status.get('uptimeEstimate', 60)  
                metrics['queries_per_second'] = round(recent_ops / max(uptime_repl, 60), 2)
            else:
                
                global_lock = server_status.get('globalLock', {})
                current_queue = global_lock.get('currentQueue', {})
                total_queue = current_queue.get('total', 0)
                active_clients = global_lock.get('activeClients', {})
                total_active = active_clients.get('total', 0)
                
                
                if total_active > 0:
                    
                    metrics['queries_per_second'] = round(total_active * 10, 2)
                else:
                    
                    metrics_data = server_status.get('metrics', {})
                    commands = metrics_data.get('commands', {})
                    
                    if commands:
                        
                        total_commands = sum(cmd.get('total', 0) for cmd in commands.values() if isinstance(cmd, dict))
                        uptime = server_status.get('uptime', 1)
                        
                        effective_uptime = max(uptime, 60)
                        metrics['queries_per_second'] = round(total_commands / effective_uptime, 2)
                    else:
                        
                        metrics['queries_per_second'] = round(metrics['active_connections'] * 0.5, 2)
        
            
            wired_tiger = server_status.get('wiredTiger', {})
            cache_stats = wired_tiger.get('cache', {})
            
            
            pages_read_into_cache = cache_stats.get('pages read into cache', 0)
            pages_requested_from_cache = cache_stats.get('pages requested from the cache', 0)
            
            if pages_requested_from_cache > 0:
                cache_hits = pages_requested_from_cache - pages_read_into_cache
                metrics['cache_hit_ratio'] = round((cache_hits / pages_requested_from_cache) * 100, 2)
            else:
                
                bytes_read = cache_stats.get('bytes read into cache', 0)
                bytes_written = cache_stats.get('bytes written from cache', 0)
                total = bytes_read + bytes_written
                
                if total > 0:
                    metrics['cache_hit_ratio'] = round((bytes_written / total) * 100, 2)
                else:
                    metrics['cache_hit_ratio'] = 0
        
            
            metrics['slow_query_count'] = 0
            metrics['avg_query_time_ms'] = 50.0
        
            client.close()
            return metrics
        
        except Exception as e:
            print(f"âŒ Error collecting MongoDB metrics: {e}")
            import traceback
            traceback.print_exc()
            raise Exception(f"Failed to collect MongoDB metrics: {str(e)}")

    @staticmethod
    async def collect_sqlite_metrics(connection_config: dict) -> Dict:
        """Collect health metrics from SQLite database"""
        conn = None
        try:
            import aiosqlite
        
            conn = await aiosqlite.connect(
                connection_config['database_name'],
                timeout=10
            )
        
            metrics = {}
        
            
            metrics['active_connections'] = 1
            metrics['max_connections'] = 1
        
        
            cursor = await conn.execute("PRAGMA page_count")
            page_count = (await cursor.fetchone())[0]
        
            cursor = await conn.execute("PRAGMA page_size")
            page_size = (await cursor.fetchone())[0]
        
            db_size_mb = (page_count * page_size) / (1024 * 1024)
            metrics['database_size_mb'] = round(db_size_mb, 2)
        
            
            cursor = await conn.execute("PRAGMA cache_size")
            cache_size = (await cursor.fetchone())[0]
        
            
            
            metrics['cache_hit_ratio'] = min(abs(cache_size) / 2000 * 100, 95.0) if cache_size else 0
        
            
            
            metrics['queries_per_second'] = 0.0
            metrics['slow_query_count'] = 0
            metrics['avg_query_time_ms'] = 1.0
        
            return metrics
        
        except Exception as e:
            print(f"Error collecting SQLite metrics: {e}")
            raise Exception(f"Failed to collect SQLite metrics: {str(e)}")
        finally:
            if conn:
                await conn.close()